### Создание Kubernetes кластера

На этом этапе необходимо создать [Kubernetes](https://kubernetes.io/ru/docs/concepts/overview/what-is-kubernetes/) кластер на базе предварительно созданной инфраструктуры.   Требуется обеспечить доступ к ресурсам из Интернета.

Это можно сделать двумя способами:

1. Рекомендуемый вариант: самостоятельная установка Kubernetes кластера.  
   а. При помощи Terraform подготовить как минимум 3 виртуальных машины Compute Cloud для создания Kubernetes-кластера. Тип виртуальной машины следует выбрать самостоятельно с учётом требовании к производительности и стоимости. Если в дальнейшем поймете, что необходимо сменить тип инстанса, используйте Terraform для внесения изменений.  
   б. Подготовить [ansible](https://www.ansible.com/) конфигурации, можно воспользоваться, например [Kubespray](https://kubernetes.io/docs/setup/production-environment/tools/kubespray/)  
   в. Задеплоить Kubernetes на подготовленные ранее инстансы, в случае нехватки каких-либо ресурсов вы всегда можете создать их при помощи Terraform.
2. Альтернативный вариант: воспользуйтесь сервисом [Yandex Managed Service for Kubernetes](https://cloud.yandex.ru/services/managed-kubernetes)  
  а. С помощью terraform resource для [kubernetes](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_cluster) создать региональный мастер kubernetes с размещением нод в разных 3 подсетях      
  б. С помощью terraform resource для [kubernetes node group](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_node_group)
  
Ожидаемый результат:

1. Работоспособный Kubernetes кластер.
2. В файле `~/.kube/config` находятся данные для доступа к кластеру.
3. Команда `kubectl get pods --all-namespaces` отрабатывает без ошибок.

---

Ответ:

Создал kubernetes cluster, kubernetes nodes & outputs. 
Дополнительно создал ServiceAccount.tf и registry.tf, посколько в документации нужно выдать права editor для puller. И добавить пару строк в outputs.

```bash
vagrant@vagrant:~/diplom$ terraform apply
yandex_vpc_network.k8s-network: Refreshing state... [id=enp7iotp4v1jkmfdqjhp]
yandex_vpc_subnet.k8s-network-a: Refreshing state... [id=e9bhkm5qp88469dpui2c]
yandex_vpc_subnet.k8s-network-c: Refreshing state... [id=b0cku4t60l9aaro4s69v]
yandex_vpc_subnet.k8s-network-b: Refreshing state... [id=e2l0tiabhp68ikg82h41]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the
following symbols:
  + create

Terraform will perform the following actions:

  # yandex_container_registry.diplom will be created
  + resource "yandex_container_registry" "diplom" {
      + created_at = (known after apply)
      + folder_id  = "b1g0kiqb05u3sdkj5l1r"
      + id         = (known after apply)
      + labels     = {
          + "my-label" = "diplom-apps"
        }
      + name       = "netology"
      + status     = (known after apply)
    }

  # yandex_container_registry_iam_binding.puller will be created
  + resource "yandex_container_registry_iam_binding" "puller" {
      + id          = (known after apply)
      + members     = (known after apply)
      + registry_id = (known after apply)
      + role        = "editor"
    }

  # yandex_iam_service_account.master will be created
  + resource "yandex_iam_service_account" "master" {
      + created_at = (known after apply)
      + folder_id  = "b1g0kiqb05u3sdkj5l1r"
      + id         = (known after apply)
      + name       = "master"
    }

  # yandex_iam_service_account.puller will be created
  + resource "yandex_iam_service_account" "puller" {
      + created_at = (known after apply)
      + folder_id  = "b1g0kiqb05u3sdkj5l1r"
      + id         = (known after apply)
      + name       = "puller"
    }

  # yandex_kubernetes_cluster.k8s-yandex will be created
  + resource "yandex_kubernetes_cluster" "k8s-yandex" {
      + cluster_ipv4_range       = (known after apply)
      + cluster_ipv6_range       = (known after apply)
      + created_at               = (known after apply)
      + description              = "description"
      + folder_id                = (known after apply)
      + health                   = (known after apply)
      + id                       = (known after apply)
      + labels                   = {
          + "my_key"       = "my_value"
          + "my_other_key" = "my_other_value"
        }
      + log_group_id             = (known after apply)
      + name                     = "k8s-yandex"
      + network_id               = "enp7iotp4v1jkmfdqjhp"
      + network_policy_provider  = "CALICO"
      + node_ipv4_cidr_mask_size = 24
      + node_service_account_id  = (known after apply)
      + release_channel          = "STABLE"
      + service_account_id       = (known after apply)
      + service_ipv4_range       = (known after apply)
      + service_ipv6_range       = (known after apply)
      + status                   = (known after apply)

      + master {
          + cluster_ca_certificate = (known after apply)
          + external_v4_address    = (known after apply)
          + external_v4_endpoint   = (known after apply)
          + external_v6_endpoint   = (known after apply)
          + internal_v4_address    = (known after apply)
          + internal_v4_endpoint   = (known after apply)
          + public_ip              = true
          + version                = "1.27"
          + version_info           = (known after apply)

          + regional {
              + region = "ru-central1"

              + location {
                  + subnet_id = "e9bhkm5qp88469dpui2c"
                  + zone      = "ru-central1-a"
                }
              + location {
                  + subnet_id = "e2l0tiabhp68ikg82h41"
                  + zone      = "ru-central1-b"
                }
              + location {
                  + subnet_id = "b0cku4t60l9aaro4s69v"
                  + zone      = "ru-central1-c"
                }
            }
        }
    }

  # yandex_kubernetes_node_group.k8snodes will be created
  + resource "yandex_kubernetes_node_group" "k8snodes" {
      + cluster_id        = (known after apply)
      + created_at        = (known after apply)
      + description       = "description"
      + id                = (known after apply)
      + instance_group_id = (known after apply)
      + labels            = {
          + "key" = "value"
        }
      + name              = "k8snodes"
      + status            = (known after apply)
      + version           = "1.27"
      + version_info      = (known after apply)

      + allocation_policy {
          + location {
              + subnet_id = (known after apply)
              + zone      = "ru-central1-a"
            }
        }

      + instance_template {
          + metadata                  = (known after apply)
          + nat                       = (known after apply)
          + network_acceleration_type = (known after apply)
          + platform_id               = "standard-v2"

          + boot_disk {
              + size = 64
              + type = "network-hdd"
            }

          + network_interface {
              + ipv4       = true
              + ipv6       = (known after apply)
              + nat        = true
              + subnet_ids = [
                  + "e9bhkm5qp88469dpui2c",
                ]
            }

          + resources {
              + core_fraction = (known after apply)
              + cores         = 4
              + gpus          = 0
              + memory        = 8
            }

          + scheduling_policy {
              + preemptible = false
            }
        }

      + scale_policy {
          + auto_scale {
              + initial = 3
              + max     = 6
              + min     = 3
            }
        }
    }

  # yandex_resourcemanager_folder_iam_member.master-editor will be created
  + resource "yandex_resourcemanager_folder_iam_member" "master-editor" {
      + folder_id = "b1g0kiqb05u3sdkj5l1r"
      + id        = (known after apply)
      + member    = (known after apply)
      + role      = "editor"
    }

Plan: 7 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + cluster_external_v4_endpoint = (known after apply)
  + cluster_id                   = (known after apply)
  + registry_id                  = (known after apply)

Do you want to perform these actions in workspace "prod"?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

yandex_iam_service_account.puller: Creating...
yandex_container_registry.diplom: Creating...
yandex_iam_service_account.master: Creating...
yandex_container_registry.diplom: Creation complete after 2s [id=crpdbp2l62e27561k4uo]
yandex_iam_service_account.puller: Creation complete after 3s [id=ajehlf0vtjs6f0dhsnfe]
yandex_container_registry_iam_binding.puller: Creating...
yandex_iam_service_account.master: Creation complete after 6s [id=aje347ls9hrqlj9f24k3]
yandex_resourcemanager_folder_iam_member.master-editor: Creating...
yandex_kubernetes_cluster.k8s-yandex: Creating...
yandex_resourcemanager_folder_iam_member.master-editor: Creation complete after 4s [id=b1g0kiqb05u3sdkj5l1r/editor/serviceAccount:aje347ls9hrqlj9f24k3]
yandex_container_registry_iam_binding.puller: Still creating... [10s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [10s elapsed]
yandex_container_registry_iam_binding.puller: Still creating... [20s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [20s elapsed]
yandex_container_registry_iam_binding.puller: Still creating... [30s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [30s elapsed]
yandex_container_registry_iam_binding.puller: Creation complete after 35s [id=crpdbp2l62e27561k4uo/editor]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [40s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [50s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m0s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m10s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m20s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m30s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m40s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [1m50s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m0s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m10s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m20s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m30s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m40s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [2m50s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m0s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m10s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m20s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m30s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m40s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [3m50s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m0s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m10s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m20s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m30s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m40s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [4m50s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Still creating... [5m0s elapsed]
yandex_kubernetes_cluster.k8s-yandex: Creation complete after 5m8s [id=catntucspbv8id1til3d]
yandex_kubernetes_node_group.k8snodes: Creating...
yandex_kubernetes_node_group.k8snodes: Still creating... [10s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [20s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [30s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [40s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [50s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m0s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m10s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m20s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m30s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m40s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [1m50s elapsed]
yandex_kubernetes_node_group.k8snodes: Still creating... [2m0s elapsed]
yandex_kubernetes_node_group.k8snodes: Creation complete after 2m6s [id=cat5pogte9bllhqon6u8]

Apply complete! Resources: 7 added, 0 changed, 0 destroyed.

Outputs:

cluster_external_v4_endpoint = "https://84.201.134.171"
cluster_id = "catntucspbv8id1til3d"
registry_id = "crpdbp2l62e27561k4uo"
```

Установил kubectl. Добавил config k8s.
```bash
vagrant@vagrant:~/diplom$ yc managed-kubernetes cluster get-credentials --id $(terraform output -json cluster_id | sed 's/\"//g') --external

Context 'yc-k8s-yandex' was added as default to kubeconfig '/home/vagrant/.kube/config'.
Check connection to cluster using 'kubectl cluster-info --kubeconfig /home/vagrant/.kube/config'.

Note, that authentication depends on 'yc' and its config profile 'netology'.
To access clusters using the Kubernetes API, please use Kubernetes Service Account.
```

```bash
vagrant@vagrant:~/diplom$ kubectl get pods --all-namespaces
NAMESPACE     NAME                                                  READY   STATUS    RESTARTS      AGE
kube-system   calico-node-tg487                                     1/1     Running   0             20m
kube-system   calico-node-v8rlp                                     1/1     Running   0             20m
kube-system   calico-node-vbfct                                     1/1     Running   0             20m
kube-system   calico-typha-564fff4699-nwdxc                         1/1     Running   0             19m
kube-system   calico-typha-horizontal-autoscaler-7d7cf6b5f9-mn65f   1/1     Running   0             23m
kube-system   calico-typha-vertical-autoscaler-7f784b789d-4rmg6     1/1     Running   3 (20m ago)   23m
kube-system   coredns-f4696fd9f-mvszw                               1/1     Running   0             23m
kube-system   coredns-f4696fd9f-tlpbr                               1/1     Running   0             20m
kube-system   ip-masq-agent-8rbkd                                   1/1     Running   0             20m
kube-system   ip-masq-agent-fpskg                                   1/1     Running   0             20m
kube-system   ip-masq-agent-mfwdc                                   1/1     Running   0             20m
kube-system   kube-dns-autoscaler-bd7cc5977-ntg2z                   1/1     Running   0             23m
kube-system   kube-proxy-5s6m4                                      1/1     Running   0             20m
kube-system   kube-proxy-ds6c9                                      1/1     Running   0             20m
kube-system   kube-proxy-m6s9l                                      1/1     Running   0             20m
kube-system   metrics-server-6f485d9c99-qfpxs                       2/2     Running   0             20m
kube-system   npd-v0.8.0-8vjpr                                      1/1     Running   0             20m
kube-system   npd-v0.8.0-s5bkb                                      1/1     Running   0             20m
kube-system   npd-v0.8.0-wh7c9                                      1/1     Running   0             20m
kube-system   yc-disk-csi-node-v2-42qnj                             6/6     Running   0             20m
kube-system   yc-disk-csi-node-v2-d7pnq                             6/6     Running   0             20m
kube-system   yc-disk-csi-node-v2-w7pns                             6/6     Running   0             20m
```